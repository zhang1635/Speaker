{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实验目标：**\n",
    "\n",
    "通过本实验，你将深入了解和实践说话人识别技术，并掌握利用声音特征进行有效说话人识别的基本方法，了解不同特征和模型对识别准确率的影响。\n",
    "\n",
    "实验的核心目标是使用TIMIT数据集来训练一个说话人识别系统，涵盖数据预处理、特征提取、模型训练和评估等关键步骤。\n",
    "\n",
    "\n",
    "**实验方法：**\n",
    "\n",
    "**1. 数据预处理和划分(可选)：**\n",
    "  - 为了方便大家，我们提供了划分好的TIMIT数据集结构，当然你也可以根据训练结果自行划分该原数据集。\n",
    "  - 原数据集下载地址：https://drive.google.com/file/d/180mSIiXN9RVDV2Xn1xcWNkMRm5J5MjN4/view?usp=sharing\n",
    "  - 我们排除了SA的两个方言句子，并在剩余的8个句子中选取了SX的5个句子和SI的1个句子作为训练集，SI的另外2个句子作为测试集。\n",
    "  \n",
    "**2. 特征提取：**\n",
    "  - 学习并实现包括但不限于MFCC特征等特征的提取，探索声音信号的频率和时间特性。\n",
    "  - 鼓励尝试和比较其他特征提取方法，例如LPCC或声谱图特征，以理解不同特征对识别性能的影响。\n",
    "  \n",
    "**3. 模型选择和训练：**\n",
    "  - 探索并选择适合的分类器和模型进行说话人识别，如GMM、Softmax分类器或深度学习模型。\n",
    "  - 实现模型训练流程，使用训练集数据训练模型。\n",
    "  \n",
    "**4. 评估和分析：**\n",
    "  - 使用准确率作为主要的评价指标在测试集上评估模型性能。\n",
    "  - 对比不同特征和模型的性能，分析其对说话人识别准确率的影响。\n",
    "  - 可视化不同模型的识别结果和错误率，讨论可能的改进方法。\n",
    "\n",
    "**实验要求：**\n",
    "  - 1.选择并实现至少一种特征的提取，并鼓励尝试其他特征提取方法。\n",
    "  - 2.选择并实现至少一种分类器或模型进行说话人识别，并使用准确率评估指标评估其性能。\n",
    "  - 3.通过实验对比、分析和可视化，撰写详细的实验报告，包括实验目的、实验方法、结果分析和结论。\n",
    "  - 4.实验报告应以清晰、逻辑性强的形式呈现，图表和结果应清楚明了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COOL\\Anaconda3\\envs\\gluon\\lib\\site-packages\\paramiko\\transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
     ]
    }
   ],
   "source": [
    "## 导入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 可以根据需要导入其他库，比如librosa用于音频处理\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据预处理(加载数据集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDir = \"E2/Dataset/TRAIN\"\n",
    "TestDir = \"E2/Dataset/TEST\"\n",
    "## 请在这里写代码加载我们划分好的TIMIT训练集和测试集\n",
    "\n",
    "# 预处理和特征提取参数\n",
    "n_mfcc = 13\n",
    "frame_length = 0.025  # 帧长25ms\n",
    "frame_stride = 0.01  #帧移10ms\n",
    "\n",
    "def extract_mfcc(audio_path, n_mfcc, frame_length, frame_stride):\n",
    "    # 加载音频文件\n",
    "    signal, sample_rate = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # 可以添加更多预处理步骤，如静音移除、预加重等\n",
    "\n",
    "    # 计算 MFCC 特征\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=n_mfcc,\n",
    "                                 n_fft=int(sample_rate * frame_length),\n",
    "                                 hop_length=int(sample_rate * frame_stride))\n",
    "    return mfccs.T  # 转置是为了将时间维度置于第一维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**调用的librosa.feature.mfcc理解：**  \n",
    "1. 参数：y是音频信号，sr是采样率，n_mfcc制定了mfcc制定了要提取的MFCC系数的数量，n_fft指定了FFT窗口大小（通过采样率和帧长度计算得到），hop_length指定了帧之间的步长（同样基于采样率和帧长度计算得到）；  \n",
    "\n",
    "2. 提取出的MFCC数据含义：第一个系数代表整个帧的能量，余下系数代表音频信号的频谱细节，但通过梅尔滤波器组和DCT，它们被转换成了梅尔频率上的倒谱（用于分离信号中的周期性结构{如说话人的声道特征}和非周期信号{噪声}，FT、对数运算、IFT）表示；  \n",
    "\n",
    "3. librosa.feature.mfcc实现思路：  \n",
    "    (1) 预加重：高通滤波音频信号，增强高频成分；  \n",
    "    (2) 窗口化：将音频信号分割成短时帧；  \n",
    "    (3) FFT：对每一帧信号进行FFT，得到频谱；  \n",
    "    (4) 梅尔滤波器组：应用一组梅尔刻度滤波器（通常是三角滤波器）到功率谱上，以模拟人耳感知；  \n",
    "    (5) 取对数：取每个梅尔滤波器输出功率的对数；  \n",
    "    (6) 离散余弦变换（DCT）：对取对数后的梅尔频谱进行DCT得到MFCC。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2772 262 13\n",
      "924 439 13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 请编写或使用库函数提取MFCC等音频特征\n",
    "# 数据预处理并进行特征提取\n",
    "def preprocess(root_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    speaker_ide = -1\n",
    "    # 遍历方言地区\n",
    "    for region_id in os.listdir(root_dir):\n",
    "        region_path = os.path.join(root_dir, region_id)\n",
    "\n",
    "        # 遍历说话人\n",
    "        for speaker_id in os.listdir(region_path):\n",
    "            speaker_path = os.path.join(region_path, speaker_id)\n",
    "            speaker_ide += 1\n",
    "            # 遍历说话人的音频文件\n",
    "            for audio_file in os.listdir(speaker_path):\n",
    "                if audio_file.startswith('SX') or audio_file.startswith('SI'):\n",
    "                    # 提取音频特征\n",
    "                    mfccs = extract_mfcc(os.path.join(speaker_path, audio_file), n_mfcc, frame_length, frame_stride)\n",
    "                    features.append(mfccs)\n",
    "                    labels.append(speaker_ide)\n",
    "    print(len(features),len(features[10]),len(features[0][0]))\n",
    "    return features, labels\n",
    "\n",
    "# mfcc可视化\n",
    "def visualize_mfcc(mfccs):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_features, train_labels = preprocess(TrainDir)\n",
    "test_features, test_labels = preprocess(TestDir)\n",
    "\n",
    "for mfcc_features in train_features:\n",
    "    visualize_mfcc(mfcc_features)\n",
    "    break  # 只展示一个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**可视化图表含义：**  \n",
    "1. 看第一个系数（最下面那行），显示了音频信号的能量变化，这在某种情况下反映了说话的节奏和强度；  \n",
    "\n",
    "2. 剩余的系数（从底部往上数），反映了信号在梅尔频率上的特性：较低的系数（比如第2个、第3个）捕捉到的是更基本的频率信息，而较高的系数则涉及更复杂的频率形状和变化；  \n",
    "\n",
    "3. 横轴表示事件变化；  \n",
    "\n",
    "4. 色彩上，蓝色表示特定频率成分较弱，红色较强。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (2772, 10127)\n",
      "Test features shape: (924, 10127)\n"
     ]
    }
   ],
   "source": [
    "## 特征标准化: 确保所有的特征均为1D arrays，并保证长度为max_length\n",
    "def pad_features(features, max_length):\n",
    "    padded_features = []\n",
    "    for f in features:\n",
    "        if isinstance(f, np.ndarray) and f.ndim == 1:  # Ensuring f is a 1D numpy array\n",
    "            if len(f) < max_length:\n",
    "                # Padding\n",
    "                padded = np.pad(f, (0, max_length - len(f)), mode='constant', constant_values=0)\n",
    "            else:\n",
    "                # Truncating if necessary\n",
    "                padded = f[:max_length]\n",
    "            padded_features.append(padded)\n",
    "        else:\n",
    "            print(\"Skipping invalid feature\")\n",
    "    return np.stack(padded_features)  # Ensuring to return a proper 2D array\n",
    "\n",
    "# Converting features to numpy arrays and ensuring they are 1D\n",
    "train_features = [np.array(f).flatten() if isinstance(f, np.ndarray) else np.array([]) for f in train_features]\n",
    "test_features = [np.array(f).flatten() if isinstance(f, np.ndarray) else np.array([]) for f in test_features]\n",
    "\n",
    "# Finding maximum length\n",
    "max_length = max(max([len(f) for f in train_features if isinstance(f, np.ndarray)]),\n",
    "                 max([len(f) for f in test_features if isinstance(f, np.ndarray)]))\n",
    "\n",
    "# Padding features\n",
    "train_features_padded = pad_features(train_features, max_length)\n",
    "test_features_padded = pad_features(test_features, max_length)\n",
    "\n",
    "print(\"Train features shape:\", train_features_padded.shape)\n",
    "print(\"Test features shape:\", test_features_padded.shape)\n",
    "\n",
    "# StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(train_features_padded)   #2772*779*13\n",
    "X_test = scaler.transform(test_features_padded)         #924*779*13\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped tensor shape: (2772, 779, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                                                                | 0/300 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm \n",
    "class SpeakerLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(SpeakerLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "      #  self.fc1 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_dim)\n",
    "        out, _ = self.lstm(x)\n",
    "        # out: (batch_size, seq_len, hidden_dim)\n",
    "        out = out[:, -1, :]  # 取最后一个时间步的输出作为最终输出\n",
    "        out = self.fc(out)\n",
    "        # out: (batch_size, num_classes)\n",
    "        return out\n",
    "\n",
    "# 示例用法\n",
    "input_dim = 13  # MFCC特征维度\n",
    "hidden_dim = 256  # LSTM隐藏层维度\n",
    "num_layers = 2  # LSTM层数\n",
    "num_classes = 462  # 说话人类别数\n",
    "\n",
    "model = SpeakerLSTM(input_dim, hidden_dim, num_layers, num_classes)\n",
    "\n",
    "# 定义交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# 将原始向量重新组织成一个三维张量\n",
    "# 1. 将原始向量分割成多个子向量，每个子向量包含 13 个元素\n",
    "X_train = np.split(X_train, 779, axis=1)\n",
    "# 2. 将这些子向量按照一定的规律排列成一个大小为 2772x779x13 的张量\n",
    "X_train = np.stack(X_train, axis=1)\n",
    "\n",
    "print(\"Reshaped tensor shape:\", X_train.shape)  # 输出：(2772, 779, 13)\n",
    "\n",
    "batch_size = 22  #22*126=2772\n",
    "input_data = X_train\n",
    "labels = y_train\n",
    "input_data = torch.from_numpy(input_data)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 定义超参数\n",
    "num_epochs = 300\n",
    "# 使用 tqdm 添加进度条\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "    # 清零梯度\n",
    "    optimizer.zero_grad()\n",
    "    # 前向传播\n",
    "    outputs = model(input_data)\n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels)\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "    # 输出当前迭代的损失\n",
    "    tqdm.write(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0021645021645021645\n"
     ]
    }
   ],
   "source": [
    "# 将原始向量重新组织成一个三维张量\n",
    "# 1. 将原始向量分割成多个子向量，每个子向量包含 13 个元素\n",
    "X_test = np.split(X_test, 779, axis=1)\n",
    "# 2. 将这些子向量按照一定的规律排列成一个大小为 2772x779x13 的张量\n",
    "X_test = np.stack(X_test, axis=1)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "all_predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    # 获取预测标签\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    # 将预测标签和真实标签添加到列表中\n",
    "    all_predictions.extend(predictions.numpy())\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, all_predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VoiceNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=60, kernel_size=7, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=60, out_channels=60, kernel_size=5, stride=2, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=60)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=60)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=512)\n",
    "        self.bn5 = nn.BatchNorm1d(num_features=512)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        # Conv2d with weights of size (H, 1) is identical to FC with H weights\n",
    "        self.conv3 = nn.Conv2d(in_channels=60, out_channels=512, kernel_size=(31, 1))\n",
    "        self.fc5 = nn.Linear(in_features=512, out_features=512)\n",
    "        self.fc6 = nn.Linear(in_features=512, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.mpool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        _, _, _, W = x.size()\n",
    "        self.apool4 = nn.AvgPool2d(kernel_size=(1, W)) # average pooling over time\n",
    "        x = self.apool4(x)\n",
    "        \n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.relu(self.bn5(self.fc5(x)))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        # during training, there's no need for SoftMax because CELoss calculates it\n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-28d2b85d4582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# 计算损失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gluon\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-b22a7b92a3b5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "model = VoiceNet(462)\n",
    "\n",
    "# 定义交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 示例输入\n",
    "batch_size = 22  \n",
    "input_data = X_train\n",
    "labels = y_train\n",
    "# 前向传播\n",
    "input_data = torch.from_numpy(input_data)\n",
    "labels = torch.tensor(labels)\n",
    "outputs = model(input_data)\n",
    "\n",
    "# 计算损失\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "\n",
    "# 更新参数\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://blog.csdn.net/qq_39373179/article/details/103788208"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
